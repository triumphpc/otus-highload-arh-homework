services:
    # Nginx балансировщик
    nginx:
      image: nginx:1.21
      container_name: nginx
      restart: unless-stopped
      depends_on:
        app1:
          condition: service_healthy
        app2:
          condition: service_healthy
      volumes:
        - ./nginx/conf.d:/etc/nginx/conf.d  # Конфиг Nginx
      ports:
        - "80:80"
        - "8080:8080"
      networks:
        - app-network

    # Первый экземпляр приложения
    app1:
      container_name: app1
      build:
        context: ..
        dockerfile: docker/app/Dockerfile
      depends_on:
        master:
            condition: service_healthy
        kafka:
            condition: service_healthy
        redis:
            condition: service_healthy
        haproxy:
          condition: service_started
      restart: on-failure:5
      ports:
        - "8082:8080"
      env_file:
        - .env
      networks:
        - app-network


      healthcheck:
        test: [ "CMD", "wget", "-q", "-O", "-", "http://localhost:8080/health" ]
        interval: 10s
        timeout: 5s
        retries: 3
        start_period: 30s

    # Второй экземпляр приложения
    app2:
      container_name: app2
      build:
        context: ..
        dockerfile: docker/app/Dockerfile
      depends_on:
        master:
          condition: service_healthy
        kafka:
          condition: service_healthy
        redis:
          condition: service_healthy
        haproxy:
          condition: service_started
      ports:
        - "8083:8080"
      restart: on-failure:5
      env_file:
        - .env
      networks:
        - app-network

      healthcheck:
        test: [ "CMD", "wget", "-q", "-O", "-", "http://localhost:8080/health" ]
        interval: 10s
        timeout: 5s
        retries: 3
        start_period: 30s

    dialog:
      container_name: dialog
      build:
        context: ..
        dockerfile: docker/dialog/Dockerfile
      ports:
        - "50051:50051"
      depends_on:
        - app1
      env_file:
        - .env
      networks:
        - app-network
      restart: unless-stopped
      healthcheck:
        test: [ "CMD", "grpc_health_probe", "-addr=:50051" ]
        interval: 10s
        timeout: 5s
        retries: 3

    feed-updater:
      container_name: feed-updater
      build:
        context: ..
        dockerfile: docker/feed-updater/Dockerfile
      ports:
        - "8081:8081"
      depends_on:
        - app1
      env_file:
        - .env
      networks:
        - app-network
      restart: unless-stopped

    master:
      container_name: master
      image: "citusdata/citus:13.0.3"
      networks:
        - app-network
      ports:
        - "5432:5432"
      environment: &AUTH
        POSTGRES_USER: "postgres"
        POSTGRES_PASSWORD: "postgres"
        POSTGRES_DB: "app_db"
        PGUSER: "postgres"
        PGPASSWORD: "postgres"
        POSTGRES_HOST_AUTH_METHOD: "trust"

    worker1:
      image: "citusdata/citus:13.0.3"
      depends_on: [ manager ]
      networks:
        - app-network
      environment: *AUTH
      command: "/wait-for-manager.sh"
      volumes:
        - healthcheck-volume:/healthcheck

    worker2:
      image: "citusdata/citus:13.0.3"
      depends_on: [ manager ]
      networks:
        - app-network
      environment: *AUTH
      command: "/wait-for-manager.sh"
      volumes:
        - healthcheck-volume:/healthcheck

    manager:
      container_name: manager
      image: "citusdata/membership-manager:0.3.0"
      volumes:
        - "${DOCKER_SOCK:-/var/run/docker.sock}:/var/run/docker.sock"
        - healthcheck-volume:/healthcheck
      depends_on: [ master ]
      networks:
        - app-network
      environment: *AUTH

    db-seeder:
      profiles:
        - seed
      container_name: db-seeder
      image: postgres:14
      depends_on:
        pgpool:
          condition: service_healthy
      env_file:
        - .env
      networks:
        - app-network
      volumes:
        - ./pg/seed.sql:/docker-entrypoint-initdb.d/seed.sql
      restart: on-failure
      command: >
        bash -c "
        while ! PGPASSWORD=$$POSTGRES_PASSWORD pg_isready -h pgpool -p 5432 -U $$POSTGRES_USER; do
        echo 'Waiting for pgpool...';
        sleep 5;
        done;
        PGPASSWORD=$$POSTGRES_PASSWORD psql -h pgpool -U $$POSTGRES_USER -d $$POSTGRES_DB -f /docker-entrypoint-initdb.d/seed.sql
        "

    # Экспортер метрик PostgreSQL для Prometheus
    postgres-exporter-1:
      image: prometheuscommunity/postgres-exporter
      container_name: postgres-exporter-1
      environment:
        - DATA_SOURCE_NAME=postgresql://postgres:postgres@master:5432/app_db?sslmode=disable
      ports:
        - "9187:9187"
      networks:
        - app-network

    postgres-exporter-2:
      image: prometheuscommunity/postgres-exporter
      container_name: postgres-exporter-2
      environment:
        - DATA_SOURCE_NAME=postgresql://postgres:postgres@worker1:5432/app_db?sslmode=disable
      ports:
        - "9188:9187"
      networks:
      - app-network

    postgres-exporter-3:
      image: prometheuscommunity/postgres-exporter
      container_name: postgres-exporter-3
      environment:
        - DATA_SOURCE_NAME=postgresql://postgres:postgres@worker2:5432/app_db?sslmode=disable
      ports:
        - "9189:9187"
      networks:
        - app-network


  # Node exporter для метрик сервера (CPU, память и т.д.)
    node-exporter:
      image: prom/node-exporter
      volumes:
        - /proc:/host/proc:ro
        - /sys:/host/sys:ro
        - /:/rootfs:ro
      command:
        - '--path.procfs=/host/proc'
        - '--path.sysfs=/host/sys'
        - '--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)'
      ports:
        - "9100:9100"
      networks:
        - app-network

    #   Prometheus для сбора метрик
    prometheus:
      container_name: prometheus
      image: prom/prometheus
      ports:
        - "9090:9090"
      volumes:
        - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      command:
        - '--config.file=/etc/prometheus/prometheus.yml'
      depends_on:
        - node-exporter
        - master
        - worker1
        - worker2
      networks:
        - app-network

    #  # Grafana для визуализации
    grafana:
      container_name: grafana
      image: grafana/grafana:latest
      ports:
        - "3000:3000"
      volumes:
        - grafana_data:/var/lib/grafana
        - ./grafana/provisioning:/etc/grafana/provisioning
      environment:
        - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER}
        - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
        - GF_SECURITY_SECRET_KEY=${GRAFANA_SECURITY_SECRET_KEY}
        - GF_USERS_ALLOW_SIGN_UP=false
        - GF_AUTH_ANONYMOUS_ENABLED=false
      depends_on:
        - prometheus
      networks:
        - app-network
      healthcheck:
        test: [ "CMD-SHELL", "wget --quiet --tries=1 --spider http://localhost:3000/api/health || exit 1" ]
        interval: 30s
        timeout: 5s
        retries: 3

    redis:
      image: redis:latest
      container_name: redis
      restart: always
      ports:
        - "6379:6379"
      volumes:
        - redis_data:/data
      networks:
        - app-network
      environment:
        - REDIS_PASSWORD=secret
      healthcheck:
        test: [ "CMD", "redis-cli", "-a", "secret", "ping" ]
        interval: 10s
        timeout: 5s
        retries: 3
      command:
        - redis-server
        - --requirepass secret
        - --save 60 1
        - --loglevel warning
        - --databases 2


#    zookeeper:
#      image: confluentinc/cp-zookeeper:latest
#      container_name: zookeeper
#      environment:
#        ZOOKEEPER_CLIENT_PORT: 2181
#        ZOOKEEPER_TICK_TIME: 2000
#      ports:
#        - "22181:2181"
#      healthcheck:
#        test: [ "CMD", "nc", "-z", "localhost", "2181" ]
#        interval: 10s
#        timeout: 5s
#        retries: 5
#      networks:
#        - app-network

    kafka:
      image: confluentinc/cp-kafka:latest
      container_name: kafka
#      depends_on:
#        zookeeper:
#          condition: service_healthy
      ports:
        - "9092:9092"
#        - "29092:29092"
        - "29093:29093"
      environment:
        KAFKA_BROKER_ID: 1
        KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT
#        KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
        KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
        KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
        KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
        KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
        KAFKA_PROCESS_ROLES: broker,controller
        KAFKA_NODE_ID: 1
        KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:29093
#        KAFKA_LISTENERS: PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092
        KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:29093
        KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
        KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
        KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
        KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
        CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
        KAFKA_ZOOKEEPER_CONNECT: ""
      healthcheck:
        test: [ "CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list" ]
        interval: 10s
        timeout: 5s
        retries: 5
      networks:
        - app-network

    kafka_create_topics:
      container_name: kafka_create_topics
      image: confluentinc/cp-kafka:latest
      depends_on:
        kafka:
          condition: service_healthy
      networks:
        - app-network
      command: >
        bash -c "
          echo 'Waiting for Kafka...';
          cub kafka-ready -b kafka:9092 1 60 &&
          kafka-topics --create --bootstrap-server kafka:9092 --topic feed_updates --partitions 1 --replication-factor 1 --if-not-exists"

    haproxy:
      image: haproxy:latest
      container_name: haproxy
      volumes:
        - ./haproxy/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
      ports:
        - "5000:5000"  # HAProxy statistics
        - "5001:5001"  # PostgreSQL via HAProxy
        - "5002:5002"  # PostgreSQL slave
      depends_on:
        - master
        - worker1
        - worker2
      env_file:
        - .env
      networks:
        - app-network
      healthcheck:
        test: [ "CMD", "pg_isready", "-h", "localhost", "-p", "5001", "-U", "postgres" ]
        interval: 10s
        timeout: 5s
        retries: 3
        start_period: 30s


volumes:
  grafana_data:
  healthcheck-volume:
  redis_data:

networks:
  app-network:
    driver: bridge
